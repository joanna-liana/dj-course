# Zadanie 4.1

Folder: `M1/embedding`

Intro:
CBOW (Continuous Bag-of-Words), jest sieciÄ… neuronowÄ…, ktÃ³ra uczy siÄ™ przewidywaÄ‡ sÅ‚owo docelowe (Å›rodkowe) na podstawie jego sÅ‚Ã³w kontekstowych (otaczajÄ…cych), znajdujÄ…cych siÄ™ w okreÅ›lonym oknie.

W pliku `M1/embedding/run-cbow.py` Å‚aduje tokenizer, tokenizuje zadane teksty i buduje w oparciu o nie model embeddingowy typu CBOW (podobieÅ„stwo/czÄ™stotliwoÅ›Ä‡ wystÄ…pieÅ„, co w odpowiednio duÅ¼ej skali zaczyna symulowaÄ‡ podobieÅ„stwo znaczeniowe - dziwnym trafem tak samo jak LLMy :))


Cel zadania: znaleÅºÄ‡ takie ustawienia aby sÅ‚owa pokrewne (np. kobieta-dziewczyna, krÃ³l-ksiÄ…Å¼Ä™ byÅ‚y blisko w embeddingu, tj. wartoÅ›Ä‡ moÅ¼liwie bliska 1)

Zadania - w skrÃ³cie:
- rozbij skrypt aby daÅ‚o siÄ™ osobno trenowaÄ‡ i osobno wnioskowaÄ‡ (teraz jest wszystko na raz :)
- wybierz sÅ‚owa/teskt referencyjny (cokolwiek wybierzesz w korpusÃ³w lub wymyÅ›lisz). Punktem odniesienia mogÄ… byÄ‡ sÅ‚owa zahardkodowane w skrypcie
- testuj trenowanie na rÃ³Å¼nych korpusach, roÅ¼nych tokenizerach, roÅ¼nych parametrach


ğŸ”¥ Nie wykonasz tego zadania bez skutecznego wykonania poprzedniego zadania. PorÃ³wnuj pomysÅ‚y na discordzie.


PrzykÅ‚adowe oczekiwane wyniki:
```
10 tokenÃ³w najbardziej podobnych do SÅOWA 'wojsko' (uÅ›rednione wektory tokenÃ³w ['wojsko']):
  > Wektor sÅ‚owa (poczÄ…tek): [ 0.8360334  0.0980003 -0.221845  -4.700161   1.4552883]...
  - wojsko: 1.0000
  - miasto: 0.6638
  - wojska: 0.6313
  - Å¼ycie: 0.6036
  - zwyciÄ™stwo: 0.5795
  - rycerstwo: 0.5671
  - paÅ„stwo: 0.5635
  - hetmanÃ³w: 0.5599
  - posiÅ‚ki: 0.5576
  - pospÃ³lstwo: 0.5331

10 tokenÃ³w najbardziej podobnych do SÅOWA 'szlachta' (uÅ›rednione wektory tokenÃ³w ['szlachta']):
  > Wektor sÅ‚owa (poczÄ…tek): [-1.5282736   0.82800084  1.1820822  -2.4249477   1.0725677 ]...
  - szlachta: 1.0000
  - piechota: 0.6810
  - jazda: 0.6259
  - sÅ‚uÅ¼ba: 0.6035
  - starszyzna: 0.6029
  - wojna: 0.5841
  - armia: 0.5670
  - arystokracja: 0.5617
  - Litwa: 0.5551
  - kupa: 0.5538

10 tokenÃ³w najbardziej podobnych do SÅOWA 'choroba' (uÅ›rednione wektory tokenÃ³w ['choroba']):
  > Wektor sÅ‚owa (poczÄ…tek): [ 0.6537147  -0.04082277 -1.689754    0.97554463  0.10579971]...
  - choroba: 1.0000
  - dziewka: 0.6708
  - mÄ™ka: 0.6616
  - natura: 0.6224
  - taka: 0.6102
  - tÄ™sknota: 0.6064
  - osoba: 0.5888
  - jakaÅ›: 0.5863
  - okrutna: 0.5849
  - zmiana: 0.5797

10 tokenÃ³w najbardziej podobnych do SÅOWA 'krÃ³l' (uÅ›rednione wektory tokenÃ³w ['krÃ³l']):
  > Wektor sÅ‚owa (poczÄ…tek): [ 2.4375966  -1.0871804  -1.6425471  -1.6709629  -0.62909025]...
  - krÃ³l: 1.0000
  - ksiÄ…Å¼Ä™: 0.7209
  - Chmielnicki: 0.6851
  - mistrz: 0.6605
  - hetman: 0.6238
  - Karol: 0.6195
  - cezar: 0.6113
  - Jurand: 0.5996
  - Bohun: 0.5919
  - jeneraÅ‚: 0.5895

10 tokenÃ³w najbardziej podobnych do kombinacji tokenÃ³w: ['dziecko', 'kobieta']
  - dziewczyna: 0.6242
  - ona: 0.6124
  - matka: 0.6069
  - dziewka: 0.6049
  - sztuka: 0.5968
  - piÄ™kna: 0.5788
  - mÄ™ka: 0.5731
  - osoba: 0.5724
  - cnota: 0.5683
  - sama: 0.5590
```

krÃ³l - ksiÄ…Å¼e - 0.7209 jest niezÅ‚e (choÄ‡ mogÅ‚oby byÄ‡ lepsze)
['dziecko', 'kobieta'] - dziewczyna: 0.6242 - teÅ¼ niezÅ‚e i teÅ¼ mogÅ‚oby byÄ‡ lepsze.

OczywiÅ›cie Å›miaÅ‚o podmieniaj sÅ‚owa.

# Zadanie 4.2

Szukamy najbardziej podobnych **zdaÅ„**: `M1/embedding/run-doc2vec.py`

Trenujemy nasz wÅ‚asny model embedingowy (dla caÅ‚ych zdaÅ„, nie samych sÅ‚Ã³w).

Zadanie - j/w - zoptymalizuj trening.

Dobierz parametry treningu (analogicznie co wczeÅ›niej) tak, aby optymalnie: zwiÄ™kszyÄ‡ jakoÅ›Ä‡ wychwytywania podobieÅ„stwa i jednoczeÅ›nie wykonywaÄ‡ trening najkrÃ³cej (tj. nie traciÄ‡ czasu i/lub nie "przetrenowaÄ‡" modelu)

W razie potrzeby dostosowuj korpus treningowy.

Zmiana ktÃ³rych parametrÃ³w najbardziej wydÅ‚uÅ¼a trening?

PrzykÅ‚adowy output (caÅ‚kiem sensowny):
```
Zdanie do wnioskowania: "Jestem gÅ‚odny i bardzo chÄ™tnie zjadÅ‚bym coÅ›."
 najbardziej podobnych zdaÅ„ z korpusu:
  - Sim: 0.6533 | Zdanie: Po chwili otworzyÅ‚ je. RzÄ™dzian siedziaÅ‚ ciÄ…gle pod oknem.
  - Sim: 0.6525 | Zdanie: â€“ ja teÅ¼ nie jem
  - Sim: 0.6487 | Zdanie: â€” Nie bÃ³j siÄ™ waÄ‡panna, nie zjem ciÄ™!
  - Sim: 0.6338 | Zdanie: â€“ ja teÅ¼ nie jem znaczy pewno zjem ale nie nie lubiÄ™ ale jest podobno taka zdrowa..
  - Sim: 0.6330 | Zdanie: â€” PrzysÅ‚aÅ‚ im je krÃ³l francuski â€” odrzekÅ‚ opat.
```
PrzykÅ‚adowy output (zdecydowanie bezsensowny):
```
Zdanie do wnioskowania: "Jestem gÅ‚odny i bardzo chÄ™tnie zjadÅ‚bym coÅ›."
5 najbardziej podobnych zdaÅ„ z korpusu:
  - Sim: 0.9350 | Zdanie: â€“ prawdopodobnie. nie nie wiesz po prostu
  - Sim: 0.9336 | Zdanie: â€“ a teraz. ktoÅ› mÄ…drze powiedziaÅ‚ Å¼e..
  - Sim: 0.9332 | Zdanie: DoÅ›Ä‡, gdy niebezpieczeÅ„stwa i Å›miaÅ‚oÅ›Ä‡ przypomnÄ™,
  - Sim: 0.9250 | Zdanie: Jestem twÃ³j stryj; choÄ‡ stary, znam, co serce mÅ‚ode;
  - Sim: 0.9207 | Zdanie: PoleciaÅ‚abym ja
```

# Zadanie 4.3

Plik `M1/embedding/run-sbert.py` - korzystamy z wczeÅ›niej wytrenowanego modelu o ktÃ³ry siÄ™ opieramy. Bierzemy nasze zdania i kodujemy je w "bazie danych" wektorowej (macierz embeddingÃ³w zdaÅ„ z naszego korpusu). I (zwyczajnie) odpytujemy tÄ™ bazÄ™ w odniesieniu do zadanego zdania (ktÃ³re wczeÅ›niej trzeba zaembedowaÄ‡).

Poszukiwanie najbliÅ¼szego wektora w wielowymiarowej przestrzeni.

**Skrypt realizuje swoje zadanie**.

Twoja rola:
- sprÃ³buj znaleÅºÄ‡ alternatywÄ™ dla modelu `SentenceTransformer(MODEL_NAME)` lepiej dostosowanego do jÄ™zyka polskiego
- rozdziel skrypt tak, aby "kodowanie bazy danych" byÅ‚o osobno a sprawdzanie zbieÅºnoÅ›ci osobno.
- odpytaj o zdania wymyÅ›lone oraz takie ktÃ³re bezpoÅ›rednio pochodzÄ… z korpusu treningowego.
